{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1575837142875,"sparkVersion":"2.3.4","uid":"regexTok_98182c2ae23a","paramMap":{"minTokenLength":1,"toLowercase":true,"gaps":true,"pattern":"\\W+","outputCol":"tokens","inputCol":"text"}}
